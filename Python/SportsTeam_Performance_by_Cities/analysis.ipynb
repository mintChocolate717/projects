{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "etc_identifier": "653a3605-5bda-4e1f-beef-04a0173d3f41",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60da2e57814a61cf6a81dd670bf35473",
     "grade": false,
     "grade_id": "cell-a6c4f74309fc2379",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Analysis of Sports Team Performance and Metropolitan Population Correlation\n",
    "\n",
    "## Project Description\n",
    "This project explores the relationship between the performance of professional sports teams (Win/Loss Ratio) and the population of their corresponding metropolitan areas. The analysis focuses on teams from the \"Big 4\" major sports leagues in the United States: NFL (football), MLB (baseball), NBA (basketball), and NHL (hockey).\n",
    "\n",
    "The data includes:\n",
    "- Metropolitan regions and associated sports teams, sourced from `wikipedia_data.html`.\n",
    "- Win/Loss statistics from league-specific files: `nfl.csv`, `mlb.csv`, `nba.csv`, and `nhl.csv`.\n",
    "\n",
    "Please keep in mind that all questions and operations are from the perspective of the metropolitan region, and that wikipedia_data.html file is the \"source of authority\" for the location of a given sports team. Thus teams which are commonly known by a different area (e.g. \"Oakland Raiders\") need to be mapped into the metropolitan region given (e.g. San Francisco Bay Area). \n",
    "\n",
    "The primary goal is to calculate the correlation between the Win/Loss ratio and the population of the city or metropolitan area where the teams are located. This correlation is calculated using the Pearson correlation coefficient (`pearsonr`), and the analysis is limited to data from the year 2018.\n",
    "\n",
    "For metropolitan areas with multiple teams in the same league, their Win/Loss ratios are averaged to obtain a single value for the city in that sport. Additionally, manual adjustments are made to match sports teams to their metropolitan areas (e.g., mapping the Oakland Raiders to the San Francisco Bay Area).\n",
    "\n",
    "## Key Questions\n",
    "- How does the Win/Loss ratio of teams in the NFL, MLB, NBA, and NHL correlate with the population of their respective metropolitan areas?\n",
    "\n",
    "## Notes for Execution\n",
    "1. The analysis excludes other sports leagues, such as MLS and CFL, to focus solely on the Big 4 leagues.\n",
    "2. For cities with multiple teams in the same league, the performance metrics are aggregated into a single representative value.\n",
    "3. Data cleaning and transformation are necessary to match team names and locations to the corresponding metropolitan areas. This may involve external research to address naming inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from Stack Overflow(https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side)\n",
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        #html_str+=f'<h2 style=\"text-align: center;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_cities_html():\n",
    "        \"\"\"\n",
    "        Cleans cities html file and returns cleaned dataframe.\n",
    "        \"\"\"\n",
    "        cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "        cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "        # let's rename columns for easier access\n",
    "        cities.rename(columns = {'Metropolitan area':'Metro. Area', 'Population (2016 est.)[8]':'Popu. Est.'}, inplace = True)\n",
    "        \n",
    "        # from here, we only clean Big 4 columns:\n",
    "        cols = ['NFL', 'MLB', 'NBA', 'NHL']\n",
    "        \n",
    "        # Strip whitespace from the specified columns\n",
    "        cities[cols] = cities[cols].select_dtypes('object').apply(lambda col: col.str.strip())\n",
    "\n",
    "        # from here, we only clean Big 4 columns:\n",
    "        cols = ['NFL', 'MLB', 'NBA', 'NHL']\n",
    "        # Step 1: Replace cells containing dashes ('—') with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace = r'.*—.*', value = np.nan, regex=True)\n",
    "        # Step 2: Remove annotations like [note X]\n",
    "        cities[cols] = cities[cols].replace(to_replace = r'(\\w*?)\\[[^\\]]+\\]', value = r'\\1', regex = True)\n",
    "        # Step 3: Replace empty strings and whitespace-only strings with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'^\\s*$', value=np.nan, regex=True)\n",
    "\n",
    "        # finally return the entire dataframe\n",
    "        return cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "369ff9ecf0ee04640574205cbc697f94",
     "grade": false,
     "grade_id": "cell-712b2b5da63d4505",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## NHL Only\n",
    "We calculate the win/loss ratio's correlation with the population of the city it is in for the **NHL** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cac4803b02502929f5b1612d48db2b5",
     "grade": false,
     "grade_id": "cell-69b16e4386e58030",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "def nhl_correlation(): \n",
    "    # Load NHL data\n",
    "    nhl_df = pd.read_csv(\"assets/nhl.csv\")\n",
    "\n",
    "    def clean_cities_html():\n",
    "        \"\"\"\n",
    "        Cleans the cities data from the HTML file and returns a DataFrame.\n",
    "        - Renames columns for easier access.\n",
    "        - Cleans the Big 4 sports columns (NFL, MLB, NBA, NHL).\n",
    "        - Replaces missing or irrelevant values (e.g., dashes, notes, empty strings).\n",
    "        \"\"\"\n",
    "        cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "        cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "\n",
    "        # Rename columns for better readability\n",
    "        cities.rename(columns={'Metropolitan area': 'Metro. Area', \n",
    "                               'Population (2016 est.)[8]': 'Popu. Est.'}, inplace=True)\n",
    "        \n",
    "        # Specify columns to clean (Big 4 sports leagues)\n",
    "        cols = ['NFL', 'MLB', 'NBA', 'NHL']\n",
    "\n",
    "        # Strip whitespace from relevant columns\n",
    "        cities[cols] = cities[cols].apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "\n",
    "        # Replace cells containing dashes ('—') with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'.*—.*', value=np.nan, regex=True)\n",
    "\n",
    "        # Remove annotations like [note X] from team names\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'(\\w*?)\\[[^\\]]+\\]', value=r'\\1', regex=True)\n",
    "\n",
    "        # Replace empty strings or whitespace-only strings with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'^\\s*$', value=np.nan, regex=True)\n",
    "\n",
    "        # Return cleaned DataFrame\n",
    "        return cities\n",
    "    \n",
    "    # Clean cities data and retain only relevant columns (Metro. Area, Population, NHL teams)\n",
    "    cities = clean_cities_html()[['Metro. Area', 'Popu. Est.', 'NHL']].dropna()\n",
    "\n",
    "    # Split NHL teams column into lists of team names for easier matching\n",
    "    cities['NHL'] = cities['NHL'].apply(lambda team: team.split())\n",
    "\n",
    "    \"\"\"NHL CSV File Cleaning\"\"\"\n",
    "    # Filter NHL data for the year 2018 and exclude division rows\n",
    "    irrelevant_rows = ['Metropolitan Division', 'Pacific Division', 'Central Division', 'Atlantic Division']\n",
    "    nhl_df = nhl_df[(nhl_df['year'] == 2018) & (~nhl_df['team'].isin(irrelevant_rows))]\n",
    "\n",
    "    # Keep only relevant columns: team, W (wins), L (losses)\n",
    "    relevant_cols = ['team', 'W', 'L']\n",
    "    nhl_df = nhl_df[relevant_cols]\n",
    "\n",
    "    # Remove asterisks from team names\n",
    "    nhl_df.replace(to_replace=r'\\*$', value='', regex=True, inplace=True)\n",
    "\n",
    "    # Calculate Win/Loss ratio for each team\n",
    "    nhl_df[['W', 'L']] = nhl_df[['W', 'L']].astype(int)  # Convert W and L columns to integers\n",
    "    nhl_df['W/L'] = nhl_df['W'] / (nhl_df['W'] + nhl_df['L'])  # Compute Win/Loss ratio\n",
    "\n",
    "    # Function to match NHL team names to their corresponding metro area\n",
    "    def match_team_city(row, sports_name):\n",
    "        for _, cities_row in cities.iterrows():\n",
    "            if any(team in row['team'] for team in cities_row[sports_name]):  # Check for team matches\n",
    "                return cities_row['Metro. Area']\n",
    "        return np.nan  # Return NaN if no match is found\n",
    "\n",
    "    # Add a Metro. Area column to NHL data by applying the matching function\n",
    "    nhl_df['Metro. Area'] = nhl_df.apply(match_team_city, sports_name='NHL', axis=1)\n",
    "\n",
    "    # Merge NHL data with cities data on Metro. Area and drop unnecessary columns\n",
    "    by_cities_df = pd.merge(nhl_df, cities, on='Metro. Area').drop(['W', 'L', 'NHL'], axis='columns')\n",
    "\n",
    "    # Group data by Metro. Area and calculate mean W/L ratio and population estimate\n",
    "    by_cities_df = by_cities_df.groupby(by='Metro. Area').agg({'Popu. Est.': 'first', 'W/L': 'mean'})\n",
    "\n",
    "    # Convert population estimates to numeric type\n",
    "    by_cities_df['Popu. Est.'] = pd.to_numeric(by_cities_df['Popu. Est.'])\n",
    "\n",
    "    # Extract relevant Series for correlation\n",
    "    population_by_region = by_cities_df['Popu. Est.']  # Metro area population\n",
    "    win_loss_by_region = by_cities_df['W/L']         # Average W/L ratio by metro area\n",
    "\n",
    "    # Assertions for data validation\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q1: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q1: There should be 28 teams being analyzed for NHL\"\n",
    "    \n",
    "    # Compute and return Pearson correlation coefficient\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52a581df513c71153e105b93764cda4b",
     "grade": true,
     "grade_id": "cell-ebe0b2dfe1067e63",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "988912cae4968d81473f46d783e79c16",
     "grade": false,
     "grade_id": "cell-cb964e690298b71d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## NBA Only\n",
    "We calculate the win/loss ratio's correlation with the population of the city it is in for the **NBA** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9394222aafc8ccab0a228098ba0d6010",
     "grade": false,
     "grade_id": "cell-5a5f21279e3d3572",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "def nba_correlation():\n",
    "    \"\"\"\n",
    "    Calculates the correlation between metropolitan area population \n",
    "    and NBA team performance (W/L%) for the year 2018.\n",
    "    \"\"\"\n",
    "    # Load NBA data\n",
    "    nba_df = pd.read_csv(\"assets/nba.csv\")\n",
    "\n",
    "    def clean_cities_html():\n",
    "        \"\"\"\n",
    "        Cleans the cities data from the HTML file and returns a DataFrame.\n",
    "        \n",
    "        Steps performed:\n",
    "        - Renames columns for better readability.\n",
    "        - Cleans the Big 4 sports columns (NFL, MLB, NBA, NHL):\n",
    "            - Strips whitespace from strings.\n",
    "            - Replaces cells containing dashes ('—') with NaN.\n",
    "            - Removes annotations like [note X].\n",
    "            - Replaces empty or whitespace-only strings with NaN.\n",
    "        \"\"\"\n",
    "        # Load data from the HTML file and select relevant columns\n",
    "        cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "        cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "\n",
    "        # Rename columns for clarity\n",
    "        cities.rename(columns={'Metropolitan area': 'Metro. Area', \n",
    "                               'Population (2016 est.)[8]': 'Popu. Est.'}, inplace=True)\n",
    "        \n",
    "        # Specify columns to clean (Big 4 sports leagues)\n",
    "        cols = ['NFL', 'MLB', 'NBA', 'NHL']\n",
    "\n",
    "        # Step 1: Strip whitespace from all relevant columns\n",
    "        cities[cols] = cities[cols].apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "\n",
    "        # Step 2: Replace cells containing dashes ('—') with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'.*—.*', value=np.nan, regex=True)\n",
    "\n",
    "        # Step 3: Remove annotations like [note X] from team names\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'(\\w*?)\\[[^\\]]+\\]', value=r'\\1', regex=True)\n",
    "\n",
    "        # Step 4: Replace empty or whitespace-only strings with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'^\\s*$', value=np.nan, regex=True)\n",
    "\n",
    "        return cities\n",
    "\n",
    "    # Step 1: Clean cities data and retain relevant columns\n",
    "    cities = clean_cities_html()[['Metro. Area', 'Popu. Est.', 'NBA']].dropna()\n",
    "\n",
    "    # Step 2: Split NBA teams column into lists of team names for easier matching\n",
    "    cities['NBA'] = cities['NBA'].apply(lambda team: team.split())\n",
    "\n",
    "    # Step 3: Filter NBA data for the year 2018\n",
    "    nba_df = nba_df[nba_df['year'] == 2018][['team', 'W/L%']]\n",
    "    \n",
    "    # Step 4: Rename 'W/L%' column for consistency\n",
    "    nba_df.rename(columns={'W/L%': 'W/L'}, inplace=True)\n",
    "\n",
    "    # Step 5: Clean team names in the NBA dataset\n",
    "    # Remove unnecessary characters such as '*' and numbers in parentheses '(#)'\n",
    "    nba_df['team'] = nba_df['team'].replace(to_replace=r'[\\s|\\*]*\\(\\d+\\)', value='', regex=True).str.strip()\n",
    "\n",
    "\n",
    "    # Step 6: Match NBA team names to their corresponding metro area\n",
    "    def match_team_city(row, sports_name):\n",
    "        \"\"\"\n",
    "        Matches a team's name to its corresponding metropolitan area using the cities DataFrame.\n",
    "        \"\"\"\n",
    "        for _, cities_row in cities.iterrows():\n",
    "            if any(team in row['team'] for team in cities_row[sports_name]):  # Check for team matches\n",
    "                return cities_row['Metro. Area']\n",
    "        return np.nan  # Return NaN if no match is found\n",
    "\n",
    "    # Apply the matching function to add 'Metro. Area' to the NBA DataFrame\n",
    "    nba_df['Metro. Area'] = nba_df.apply(lambda row: match_team_city(row, sports_name='NBA'), axis=1)\n",
    "\n",
    "    # Step 7: Merge NBA data with cities data on 'Metro. Area'\n",
    "    by_cities_df = pd.merge(nba_df, cities, on='Metro. Area')\n",
    "\n",
    "    # Step 8: Convert population estimates and W/L ratios to numeric types\n",
    "    by_cities_df['Popu. Est.'] = pd.to_numeric(by_cities_df['Popu. Est.'])\n",
    "    by_cities_df['W/L'] = pd.to_numeric(by_cities_df['W/L'])\n",
    "\n",
    "    # Step 9: Group data by 'Metro. Area' and calculate mean W/L ratio and population estimate\n",
    "    by_cities_df = by_cities_df.groupby(by='Metro. Area').agg({'Popu. Est.': 'first', 'W/L': 'mean'})\n",
    "\n",
    "    # Step 10: Extract relevant data for correlation\n",
    "    population_by_region = by_cities_df['Popu. Est.']  # Metro area population\n",
    "    win_loss_by_region = by_cities_df['W/L']           # Average W/L ratio by metro area\n",
    "\n",
    "    # Step 11: Validate data length and consistency\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q2: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q2: There should be 28 teams being analyzed for NBA\"\n",
    "\n",
    "    # Step 12: Compute and return Pearson correlation coefficient\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbdeb8eb22f525a34c10dc8798324e42",
     "grade": true,
     "grade_id": "cell-e573b2b4a282b470",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a1a5809f675ca033086422007cd73bd",
     "grade": false,
     "grade_id": "cell-96e15e4335df78f4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## MLB Only\n",
    "We calculate the win/loss ratio's correlation with the population of the city it is in for the **MLB** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27e8c0da6c9fa0dffc10488314335b6c",
     "grade": false,
     "grade_id": "cell-33b00fc3f3467b0c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def mlb_correlation():\n",
    "    \"\"\"\n",
    "    Calculates the correlation between metropolitan area population \n",
    "    and MLB team performance (W/L%) for the year 2018.\n",
    "    \"\"\"\n",
    "    # Load MLB data\n",
    "    mlb_df = pd.read_csv(\"assets/mlb.csv\")\n",
    "\n",
    "    def clean_cities_html():\n",
    "        \"\"\"\n",
    "        Cleans the cities data from the HTML file and returns a DataFrame.\n",
    "        \n",
    "        Steps performed:\n",
    "        - Renames columns for better readability.\n",
    "        - Cleans the Big 4 sports columns (NFL, MLB, NBA, NHL):\n",
    "            - Strips whitespace from strings.\n",
    "            - Replaces cells containing dashes ('—') with NaN.\n",
    "            - Removes annotations like [note X].\n",
    "            - Replaces empty or whitespace-only strings with NaN.\n",
    "        \"\"\"\n",
    "        # Load data from the HTML file and select relevant columns\n",
    "        cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "        cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "\n",
    "        # Rename columns for clarity\n",
    "        cities.rename(columns={'Metropolitan area': 'Metro. Area', \n",
    "                               'Population (2016 est.)[8]': 'Popu. Est.'}, inplace=True)\n",
    "        \n",
    "        # Specify columns to clean (Big 4 sports leagues)\n",
    "        cols = ['NFL', 'MLB', 'NBA', 'NHL']\n",
    "\n",
    "        # Step 1: Strip whitespace from all relevant columns\n",
    "        cities[cols] = cities[cols].apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "\n",
    "        # Step 2: Replace cells containing dashes ('—') with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'.*—.*', value=np.nan, regex=True)\n",
    "\n",
    "        # Step 3: Remove annotations like [note X] from team names\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'(\\w*?)\\[[^\\]]+\\]', value=r'\\1', regex=True)\n",
    "\n",
    "        # Step 4: Replace empty or whitespace-only strings with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'^\\s*$', value=np.nan, regex=True)\n",
    "\n",
    "        return cities\n",
    "\n",
    "    # Step 1: Clean cities data and retain relevant columns\n",
    "    cities = clean_cities_html()[['Metro. Area', 'Popu. Est.', 'MLB']].dropna()\n",
    "\n",
    "    # Step 2: Split MLB teams column into lists of team names for easier matching\n",
    "    cities['MLB'] = cities['MLB'].apply(lambda team: team.split())\n",
    "\n",
    "    # Step 3: Filter MLB data for the year 2018 and retain relevant columns\n",
    "    mlb_df = mlb_df[mlb_df['year'] == 2018][['team', 'W-L%']]\n",
    "\n",
    "    # Step 4: Rename 'W-L%' column for consistency\n",
    "    mlb_df.rename(columns={'W-L%': 'W/L'}, inplace=True)\n",
    "\n",
    "    # Step 5: Clean team names in the MLB dataset\n",
    "    mlb_df['team'] = mlb_df['team'].str.strip()\n",
    "\n",
    "    # Step 6: Match MLB team names to their corresponding metro area\n",
    "    def match_team_city(row, sports_name):\n",
    "        \"\"\"\n",
    "        Matches a team's name to its corresponding metropolitan area using the cities DataFrame.\n",
    "        \"\"\"\n",
    "        for _, cities_row in cities.iterrows():\n",
    "            if any(team in row['team'] for team in cities_row[sports_name]):  # Check for team matches\n",
    "                return cities_row['Metro. Area']\n",
    "        return np.nan  # Return NaN if no match is found\n",
    "\n",
    "    # Apply the matching function to add 'Metro. Area' to the MLB DataFrame\n",
    "    mlb_df['Metro. Area'] = mlb_df.apply(lambda row: match_team_city(row, sports_name='MLB'), axis=1)\n",
    "\n",
    "    # Step 7: Manually overwrite mismatched metro areas for specific teams\n",
    "    mlb_df.loc[mlb_df['team'] == 'Boston Red Sox', 'Metro. Area'] = 'Boston'\n",
    "    mlb_df.loc[mlb_df['team'] == 'Cincinnati Reds', 'Metro. Area'] = 'Cincinnati'\n",
    "\n",
    "    # Step 8: Merge MLB data with cities data on 'Metro. Area'\n",
    "    by_cities_df = pd.merge(mlb_df, cities, on='Metro. Area')\n",
    "\n",
    "    # Step 9: Convert population estimates and W/L ratios to numeric types\n",
    "    by_cities_df['Popu. Est.'] = pd.to_numeric(by_cities_df['Popu. Est.'])\n",
    "    by_cities_df['W/L'] = pd.to_numeric(by_cities_df['W/L'])\n",
    "\n",
    "    # Step 10: Group data by 'Metro. Area' and calculate mean W/L ratio and population estimate\n",
    "    by_cities_df = by_cities_df.groupby(by='Metro. Area').agg({'Popu. Est.': 'first', 'W/L': 'mean'})\n",
    "\n",
    "    # Step 11: Extract relevant data for correlation\n",
    "    population_by_region = by_cities_df['Popu. Est.']  # Metro area population\n",
    "    win_loss_by_region = by_cities_df['W/L']           # Average W/L ratio by metro area\n",
    "\n",
    "    # Step 12: Validate data length and consistency\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analyzed for MLB\"\n",
    "\n",
    "    # Step 13: Compute and return Pearson correlation coefficient\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cda33b094ba19ccc37a481e0dd29e0bc",
     "grade": true,
     "grade_id": "cell-764d4476f425c5a2",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6977a6da9ed6d8b7a0b7e37bbeda709b",
     "grade": false,
     "grade_id": "cell-793df6c04dfb126e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## NFL Only\n",
    "We calculate the win/loss ratio's correlation with the population of the city it is in for the **NFL** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4914ad1e119278ec2bd567c52640b66",
     "grade": false,
     "grade_id": "cell-8ccebc209aeec8d9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004282141436393022"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "nfl_df = pd.read_csv(\"assets/nfl.csv\")\n",
    "\n",
    "def nfl_correlation(): \n",
    "    # Load NFL data\n",
    "    nfl_df = pd.read_csv(\"assets/nfl.csv\")\n",
    "\n",
    "    def clean_cities_html():\n",
    "        \"\"\"\n",
    "        Cleans the cities data from the HTML file and returns a DataFrame.\n",
    "        \n",
    "        Steps performed:\n",
    "        - Renames columns for better readability.\n",
    "        - Cleans the Big 4 sports columns (NFL, MLB, NBA, NHL):\n",
    "            - Strips whitespace from strings.\n",
    "            - Replaces cells containing dashes ('—') with NaN.\n",
    "            - Removes annotations like [note X].\n",
    "            - Replaces empty or whitespace-only strings with NaN.\n",
    "        \"\"\"\n",
    "        # Load data from the HTML file and select relevant columns\n",
    "        cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "        cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "\n",
    "        # Rename columns for clarity\n",
    "        cities.rename(columns={'Metropolitan area': 'Metro. Area', \n",
    "                               'Population (2016 est.)[8]': 'Popu. Est.'}, inplace=True)\n",
    "        \n",
    "        # Specify columns to clean (Big 4 sports leagues)\n",
    "        cols = ['NFL', 'MLB', 'NBA', 'NHL']\n",
    "\n",
    "        # Step 1: Strip whitespace from all relevant columns\n",
    "        cities[cols] = cities[cols].apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "\n",
    "        # Step 2: Replace cells containing dashes ('—') with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'.*—.*', value=np.nan, regex=True)\n",
    "\n",
    "        # Step 3: Remove annotations like [note X] from team names\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'(\\w*?)\\[[^\\]]+\\]', value=r'\\1', regex=True)\n",
    "\n",
    "        # Step 4: Replace empty or whitespace-only strings with NaN\n",
    "        cities[cols] = cities[cols].replace(to_replace=r'^\\s*$', value=np.nan, regex=True)\n",
    "\n",
    "        return cities\n",
    "\n",
    "    # Step 1: Clean cities data and retain relevant columns\n",
    "    cities = clean_cities_html()[['Metro. Area', 'Popu. Est.', 'NFL']].dropna()\n",
    "\n",
    "    # Step 2: Split MLB teams column into lists of team names for easier matching\n",
    "    cities['NFL'] = cities['NFL'].apply(lambda team: team.split())\n",
    "\n",
    "    # Step 3: Filter MLB data for the year 2018 and retain relevant columns\n",
    "    nfl_df = nfl_df[nfl_df['year'] == 2018][['team', 'W-L%']]\n",
    "\n",
    "    # Step 4: Rename 'W-L%' column for consistency\n",
    "    nfl_df.rename(columns={'W-L%': 'W/L'}, inplace=True)\n",
    "\n",
    "    # Step 4.5: Drop all divider rows that contain names like 'AFC North'\n",
    "    nfl_df = nfl_df[~nfl_df['team'].str.contains('AFC|NFC')]\n",
    "\n",
    "    # Step 5: Clean team names in the NFL dataset\n",
    "    # Remove unnecessary characters such as '*' or '+'\n",
    "    nfl_df['team'] = nfl_df['team'].replace(to_replace=r'\\*|\\+', value = '', regex=True).str.strip()\n",
    "\n",
    "    # Step 6: Match NFL team names to their corresponding metro area\n",
    "    def match_team_city(row, sports_name):\n",
    "        \"\"\"\n",
    "        Matches a team's name to its corresponding metropolitan area using the cities DataFrame.\n",
    "        \"\"\"\n",
    "        for _, cities_row in cities.iterrows():\n",
    "            if any(team in row['team'] for team in cities_row[sports_name]):  # Check for team matches\n",
    "                return cities_row['Metro. Area']\n",
    "        return np.nan  # Return NaN if no match is found\n",
    "\n",
    "    # Apply the matching function to add 'Metro. Area' to the NFl DataFrame\n",
    "    nfl_df['Metro. Area'] = nfl_df.apply(lambda row: match_team_city(row, sports_name='NFL'), axis=1)\n",
    "\n",
    "    # Step 7: Manually overwrite mismatched metro areas for specific teams\n",
    "    nfl_df.loc[nfl_df['team'] == 'Boston Red Sox', 'Metro. Area'] = 'Boston'\n",
    "    nfl_df.loc[nfl_df['team'] == 'Cincinnati Reds', 'Metro. Area'] = 'Cincinnati'\n",
    "\n",
    "    # Step 8: Merge NFL data with cities data on 'Metro. Area'\n",
    "    by_cities_df = pd.merge(nfl_df, cities, on='Metro. Area')\n",
    "\n",
    "    # Step 9: Convert population estimates and W/L ratios to numeric types\n",
    "    by_cities_df['Popu. Est.'] = pd.to_numeric(by_cities_df['Popu. Est.'])\n",
    "    by_cities_df['W/L'] = pd.to_numeric(by_cities_df['W/L'])\n",
    "\n",
    "    # Step 10: Group data by 'Metro. Area' and calculate mean W/L ratio and population estimate\n",
    "    by_cities_df = by_cities_df.groupby(by='Metro. Area').agg({'Popu. Est.': 'first', 'W/L': 'mean'})\n",
    "\n",
    "    # Step 11: Extract relevant data for correlation\n",
    "    population_by_region = by_cities_df['Popu. Est.']  # Metro area population\n",
    "    win_loss_by_region = by_cities_df['W/L']           # Average W/L ratio by metro area\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q4: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 29, \"Q4: There should be 29 teams being analysed for NFL\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
    "\n",
    "nfl_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9415d6399aa49e3a1a60813afdefa3b",
     "grade": true,
     "grade_id": "cell-de7b148b9554dbda",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b02d5cd3273f561e4ae939bb2a41740c",
     "grade": false,
     "grade_id": "cell-97b49d8639e908c4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## All Together\n",
    "Alright, so here's what I'm doing for this part: I'm testing the idea that **if a metro area has teams in two different sports, those teams will perform similarly in their respective sports.** To check this, I'm running a series of paired t-tests (using `ttest_rel` from `scipy.stats`) for all pairs of sports. Essentially, I want to see if there are any sports where we can confidently reject the null hypothesis (that their performances are the same). \n",
    "\n",
    "For regions with multiple teams in the same sport, I'll calculate the average performance to represent that sport in that city. Also, I'll only include cities that have teams participating in both sports being compared, and I'll drop cities that don't fit the criteria. This part is pretty important because it’s worth 20% of the assignment grade!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d78c961eb66f8d8c81f06d33ae8f393",
     "grade": false,
     "grade_id": "cell-92f25f44b8d1179f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def sports_team_performance():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Note: p_values is a full dataframe, so df.loc[\"NFL\",\"NBA\"] should be the same as df.loc[\"NBA\",\"NFL\"] and\n",
    "    # df.loc[\"NFL\",\"NFL\"] should return np.nan\n",
    "    sports = ['NFL', 'NBA', 'NHL', 'MLB']\n",
    "    p_values = pd.DataFrame({k:np.nan for k in sports}, index=sports)\n",
    "    \n",
    "    assert abs(p_values.loc[\"NBA\", \"NHL\"] - 0.02) <= 1e-2, \"The NBA-NHL p-value should be around 0.02\"\n",
    "    assert abs(p_values.loc[\"MLB\", \"NFL\"] - 0.80) <= 1e-2, \"The MLB-NFL p-value should be around 0.80\"\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a596ab421a45cc01168d10e8fbb8f89",
     "grade": true,
     "grade_id": "cell-fb4b9cb5ff4570a6",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
